# 20251117-20251123

## 2025-11-18

- **[arXiv2511] A Meta-Heuristic Load Balancer for Cloud Computing Systems**
  - **tags:** [mlsys], [scheduling], [load balancing, cloud computing, genetic algorithm, meta-heuristic, resource allocation]
  - **authors:** Leszek Sliwko, Vladimir Getov
  - **institution:** University of Westminster
  - **link:** https://arxiv.org/pdf/2511.11721v2
  - **Simple LLM Summary:** This paper proposes a meta-heuristic load balancing strategy for cloud systems using a novel genetic algorithm seeded with outputs from other meta-heuristics. The approach considers multiple resource types and service migration costs while maintaining system stability. Experimental results demonstrate effective resource allocation with minimum cost in cloud computing environments.

- **[arXiv2511] 10Cache: Heterogeneous Resource-Aware Tensor Caching and Migration for LLM Training**
  - **tags:** [mlsys], [LLM training], [tensor caching, memory offloading, GPU optimization, heterogeneous memory, prefetching]
  - **authors:** Sabiha Afroz, Redwan Ibne Seraj Khan, Hadeel Albahar, Jingoo Han, Ali R. Butt
  - **institution:** Virginia Tech, Kuwait University
  - **link:** https://arxiv.org/pdf/2511.14124v1
  - **Simple LLM Summary:** 10Cache introduces a resource-aware tensor caching and migration system that coordinates memory usage across GPU, CPU, and NVMe tiers by profiling tensor execution order for prefetching and optimizing memory buffer allocation. It achieves up to 2× training speedup and significantly improves GPU cache hit rates and memory utilization compared to state-of-the-art offloading methods. The system demonstrates practical scalability for optimizing LLM training throughput in cloud environments.

- **[arXiv2511] Parallelizing Tree Search with Twice Sequential Monte Carlo**
  - **tags:** [mlsys], [Other models inference], [reinforcement learning, tree search, sequential monte carlo, parallelization, variance reduction, path degeneracy]
  - **authors:** Yaniv Oren, Joery A. de Vries, Pascal R. van der Vaart, Matthijs T. J. Spaan, Wendelin Böhmer
  - **institution:** Delft University of Technology
  - **link:** https://arxiv.org/pdf/2511.14220v1
  - **Simple LLM Summary:** The paper introduces Twice Sequential Monte Carlo Tree Search (TSMCTS) to address variance and path degeneracy issues in Sequential Monte Carlo methods for reinforcement learning. TSMCTS outperforms both SMC baselines and modern MCTS variants across discrete and continuous environments. It achieves better scaling with search depth while maintaining the parallelization advantages of SMC methods.

- **[arXiv2511] Hyperion: Hierarchical Scheduling for Parallel LLM Acceleration in Multi-tier Networks**
  - **tags:** [mlsys], [LLM inference], [hierarchical scheduling, model partitioning, multi-tier networks, edge computing, latency optimization]
  - **authors:** Mulei Ma, Minrui Xu, Zihan Chen, Yang Yang, Tony Q. S. Quek
  - **institution:** ShanghaiTech University, Singapore University of Technology and Design
  - **link:** https://arxiv.org/pdf/2511.14450v1
  - **Simple LLM Summary:** Hyperion proposes a hierarchical two-stage framework that combines offline inter-tier model partitioning with online intra-tier scheduling to optimize LLM inference in multi-tier networks. The system uses Binary Search with Dynamic Programming for partitioning and Adaptive Real-time Task Scheduling for request distribution. Experimental results show Hyperion reduces end-to-end latency by up to 52.1% compared to GPipe while maintaining higher GPU utilization and better scalability for long-sequence generation.

- **[arXiv2511] MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts**
  - **tags:** [mlsys], [LLM inference], [mixture-of-experts, speculative execution, expert offloading, prefetching, quantization, inference optimization]
  - **authors:** Wenfeng Wang, Jiacheng Liu, Xiaofeng Hou, Xinfeng Xia, Peng Tang, Mingxuan Zhang, Chao Li, Minyi Guo
  - **institution:** Shanghai Jiao Tong University, Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2511.14102v1
  - **Simple LLM Summary:** MoE-SpeQ introduces a speculative execution system that uses a small draft model to predict future expert requirements, enabling proactive prefetching and overlapping I/O with computation. The system employs an adaptive governor guided by an Amortization Roofline Model to dynamically optimize speculation strategies. Evaluation shows up to 2.34× speedup over existing offloading frameworks, making MoE inference more efficient on memory-constrained hardware.

- **[arXiv2511] FailSafe: High-performance Resilient Serving**
  - **tags:** [mlsys], [LLM inference], [fault tolerance, tensor parallelism, KVCache optimization, load balancing, GPU failure recovery]
  - **authors:** Ziyi Xu, Zhiqiang Xie, Swapnil Gandhi, Christos Kozyrakis
  - **institution:** Shanghai Jiao Tong University, Stanford University, NVIDIA Research
  - **link:** https://arxiv.org/pdf/2511.14116v1
  - **Simple LLM Summary:** FailSafe introduces three key techniques - cyclic KVCache placement, hybrid attention, and fine-grained load-aware routing - along with proactive KVCache backup and on-demand weight recovery to maintain high-performance LLM serving under GPU failures. The system achieves up to 2x higher throughput and two orders of magnitude lower recovery latency compared to standard approaches, sustaining balanced utilization even with multiple GPU failures.

- **[arXiv2511] A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation**
  - **tags:** [mlsys], [Other models inference], [wearable sensors, action recognition, stress estimation, archery, LSTM, MLP, accelerometer, PPG, HRV]
  - **authors:** Xianghe Liu, Jiajia Liu, Chuxian Xu, Minghan Wang, Hongbo Peng, Tao Sun, Jiaqi Xu
  - **institution:** Beijing PsychTech Technology Co., Ltd.
  - **link:** https://arxiv.org/pdf/2511.14057v1
  - **Simple LLM Summary:** The paper proposes a multimodal framework using wrist-worn sensors with accelerometer and PPG data for archery action recognition and stress estimation. It introduces Smoothed Differential Acceleration features with LSTM for motion phase classification and HRV features with MLP for stress level detection. The integrated approach demonstrates effective monitoring of both biomechanical and psychological states in precision sports.

- **[arXiv2511] Algebraformer: A Neural Approach to Linear Systems**
  - **tags:** [mlsys], [Other models inference], [linear systems, transformer architecture, ill-conditioned systems, scientific computing, neural networks]
  - **authors:** Pietro Sittoni, Francesco Tudisco
  - **institution:** Gran Sasso Science Institute, University of Edinburgh, Miniml.AI
  - **link:** https://arxiv.org/pdf/2511.14263v1
  - **Simple LLM Summary:** The paper proposes Algebraformer, a Transformer-based neural architecture that solves linear systems end-to-end with a novel encoding scheme achieving O(n²) memory complexity. It demonstrates effectiveness on ill-conditioned systems from spectral methods and Newton method acceleration. The approach achieves competitive accuracy with lower computational overhead, showing neural architectures can reduce complexity in scientific computing pipelines.

- **[arXiv2511] From Graphs to Hypergraphs: Enhancing Aspect-Based Sentiment Analysis via Multi-Level Relational Modeling**
  - **tags:** [mlsys], [Other models inference], [Aspect-Based Sentiment Analysis, Hypergraph Neural Networks, Hierarchical Clustering]
  - **authors:** Omkar Mahesh Kashyap, Padegal Amit, Madhav Kashyap, Ashwini M Joshi, Shylaja SS
  - **institution:** PES University, University of Washington
  - **link:** https://arxiv.org/pdf/2511.14142v1
  - **Simple LLM Summary:** The paper proposes HyperABSA, a dynamic hypergraph framework that constructs aspect-opinion structures using sample-specific hierarchical clustering with an acceleration-fallback cutoff. Experiments show consistent improvements over graph baselines on three benchmarks, demonstrating hypergraphs as an efficient and powerful alternative for ABSA tasks. The method achieves substantial gains when combined with RoBERTa backbones, particularly effective for short-text scenarios.

- **[arXiv2511] Tele-LLM-Hub: Building Context-Aware Multi-Agent LLM Systems for Telecom Networks**
  - **tags:** [mlsys], [LLM training, finetuning], [multi-agent systems, telecom networks, context-aware communication, low-code platform, 5G/6G networks]
  - **authors:** Pranshav Gajjar, Cong Shen, Vijay K Shah
  - **institution:** North Carolina State University, University of Virginia
  - **link:** https://arxiv.org/pdf/2511.09087v2
  - **Simple LLM Summary:** This paper introduces Tele-LLM-Hub, a low-code platform that implements the Telecom Model Context Protocol (TeleMCP) to enable structured communication between context-aware multi-agent LLM systems in telecom environments. The system provides tools for agent creation, workflow composition, and integration with telecom software stacks through specialized components like Agent Maker and MA-Maker. The framework aims to democratize the design of multi-agent LLM systems and accelerate innovation in next-generation wireless networks by enabling domain-specific agent coordination and communication.
