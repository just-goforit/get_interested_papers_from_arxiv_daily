# 20251027-20251102

## 2025-10-28

- **[arXiv2510] TokenTiming: A Dynamic Alignment Method for Universal Speculative
  Decoding Model Pairs**
  - **tags:** [mlsys], [LLM inference], [speculative decoding, vocabulary alignment, dynamic time warping, token re-encoding, probability distribution transfer]
  - **authors:** Sibo Xiao, Jinyuan Fu, Zhongle Xie, Lidan Shou
  - **institution:** Zhejiang University
  - **link:** http://arxiv.org/pdf/2510.15545v2
  - **Simple LLM Summary:** TokenTiming introduces a dynamic alignment method using Dynamic Time Warping to enable speculative decoding between models with mismatched vocabularies. It re-encodes draft token sequences and transfers probability distributions without requiring model retraining. The approach achieves 1.57x speedup and makes draft model selection more flexible for LLM acceleration.

- **[arXiv2510] CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement
  Learning**
  - **tags:** [mlsys], [kernels], [CUDA optimization, reinforcement learning, contrastive learning, GPU computing, automated code optimization]
  - **authors:** Xiaoya Li, Xiaofei Sun, Albert Wang, Jiwei Li, Chris Shum
  - **institution:** DeepReinforce
  - **link:** http://arxiv.org/pdf/2507.14111v8
  - **Simple LLM Summary:** CUDA-L1 introduces a contrastive reinforcement learning framework that transforms LLMs into effective CUDA optimizers using speedup-based rewards. The method achieves significant performance improvements across multiple GPU architectures, with average speedups of 3.12x on A100. It autonomously discovers and combines optimization techniques while identifying performance bottlenecks without requiring human expertise.
